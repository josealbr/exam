{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [95-865] Unstructured Data Analysis: Final Exam Q1\n",
    "\n",
    "Name:  \n",
    "Andrew ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1:  Sentiment Analysis [Total: 25 Points]\n",
    "\n",
    "Universal Brothers, a fictional movie production company approaches you to find out whether people like the movies the produce.\n",
    "Download the dataset from https://www.dropbox.com/s/1ztjhjsznlhtv10/ExamData-1.zip?dl=0 <br>\n",
    "Unzip into same folder as this notebook. Do not have the files inside any other inner folder.\n",
    "Find attached an IMDB dataset for movie reviews. You will perform sentiment analysis on this dataset. Poorly rated movies are labeled 0 and highly rated movies are labeled 1. You are provided with training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Load [1 Point]\n",
    "Load the train and test files into a dataframe. Name the columns to help you in the rest of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Clean the Dataset [4 points]\n",
    "\n",
    "- Tokenize the reviews using Spacy\n",
    "- Convert tokens to lower case\n",
    "- Only keep alphanumeric characters in the reviews\n",
    "- Use the stopwords.txt file to remove stop words from the tokens list\n",
    "- Remove punctuations from the reviews\n",
    "- Perform the above on both the train and test review datasets\n",
    "- List the tokens for the first 5 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Turning movie reviews into vectors with the help of word embeddings [Loading word embeddings - 2 points, feature matrix - 8 points]\n",
    "\n",
    "In the RNN demo, you saw how to load a pre-computed GloVe word embedding. Please repeat this to load in 50-dimensional GloVe word embedding vectors from `glove.6B.50d.txt`. \n",
    "\n",
    "A movie review is composed of words. Given a review, let's define a \"review embedding\" to be the average of the individual token (word) embeddings. Write a function to create a matrix whose rows are the review embeddings created as described in the previous sentence. If a word does not have a GloVe word embedding, ignore it. Each movie review now is an embedding vector which could be thought of as the feature vector for that movie review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write your code here for loading in GloVe word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write your code here for computing a 2D numpy array of review embeddings\n",
    "# (so the i-th movie review should having an embedding given by the i-th row of the 2D array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) SVM [Cross Validation - 6 points, Correct Prediction - 4 Points]\n",
    "We now train a polynomial kernel SVM using the review embeddings from the previous part as feature vectors. But first, we have to figure out SVM parameter $C$ and also which polynomial degree $d$ to use! We do a grid search over $C$ in the range `np.logspace(-4, 2, 3)`, and polynomial degree $d$ in the range `range(1,4)`. For each parameter choice $(C, d)$, compute the 5-fold cross validation prediction accuracy (this will be the cross validation score for $(C, d)$). Across all choices of $(C, d)$ we will use whichever one has the highest cross validation score -- this will correspond to the best $C$ and best $d$. Then train the polynomial kernel SVM using the best $C$ and best $d$ and report the accuracy on the actual test data.\n",
    "\n",
    "Note that this problem involves writing grid search cross validation code (do NOT use scikit-learn or some external resource code that does this grid search for you; this problem is asking you to complete the grid search code below!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "num_folds = 5\n",
    "k_fold = KFold(num_folds)\n",
    "C_values = np.logspace(-4, 2, 3)\n",
    "D_values = range(1, 4)\n",
    "\n",
    "arg_max = None\n",
    "max_cross_val_score = -np.inf\n",
    "for C in C_values:\n",
    "    for d in D_values:\n",
    "        ################################################################################\n",
    "        # Write your code only in this block -- do not change code outside of this block!\n",
    "        # Hint: You will want to use `k_fold` (defined above) in conjunction with your\n",
    "        # training movie review feature vectors (these are the review embeddings) as\n",
    "        # well as training labels. The code here should *not* look at any part of the\n",
    "        # test data!\n",
    "        \n",
    "        cross_val_score = 0  # this should not actually be set to 0! set it to the cross validation SVM accuracy using parameters C and d\n",
    "        \n",
    "        ################################################################################\n",
    "\n",
    "        cross_val_score = np.mean(fold_scores)\n",
    "        if cross_val_score > max_cross_val_score:\n",
    "            max_cross_val_score = cross_val_score\n",
    "            arg_max = (C, d)\n",
    "            \n",
    "best_C, best_d = arg_max\n",
    "print(best_C, best_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write your code here that trains a polynomial kernel SVM using the best C and best d\n",
    "# (and the full training dataset), and then prints out the classifier accuracy on the\n",
    "# test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
