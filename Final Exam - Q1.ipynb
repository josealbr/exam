{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [95-865] Unstructured Data Analysis: Final Exam Q1\n",
    "\n",
    "Name: Jose Alberto Rodriguez \n",
    "Andrew ID: Josealbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1:  Sentiment Analysis [Total: 25 Points]\n",
    "\n",
    "Universal Brothers, a fictional movie production company approaches you to find out whether people like the movies the produce.\n",
    "Download the dataset from https://www.dropbox.com/s/1ztjhjsznlhtv10/ExamData-1.zip?dl=0 <br>\n",
    "Unzip into same folder as this notebook. Do not have the files inside any other inner folder.\n",
    "Find attached an IMDB dataset for movie reviews. You will perform sentiment analysis on this dataset. Poorly rated movies are labeled 0 and highly rated movies are labeled 1. You are provided with training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Load [1 Point]\n",
    "Load the train and test files into a dataframe. Name the columns to help you in the rest of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0      id  sentiment                                             review\n",
       "1  5814_8          1  With all this stuff going down at the moment w...\n",
       "2  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "3  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "4  3630_4          0  It must be assumed that those who praised this..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "test = pd.read_csv('test.csv', encoding = \"ISO-8859-1\", header=None)\n",
    "train = pd.read_csv('train.csv', encoding = \"ISO-8859-1\", header=None)\n",
    "\n",
    "train.columns = ['id', 'sentiment', 'review']\n",
    "test.columns = ['id', 'sentiment', 'review']\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Clean the Dataset [4 points]\n",
    "\n",
    "- Tokenize the reviews using Spacy\n",
    "- Convert tokens to lower case\n",
    "- Only keep alphanumeric characters in the reviews\n",
    "- Use the stopwords.txt file to remove stop words from the tokens list\n",
    "- Remove punctuations from the reviews\n",
    "- Perform the above on both the train and test review datasets\n",
    "- List the tokens for the first 5 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "with open(\"stopwords.txt\") as f:\n",
    "    stopwords = f.read()\n",
    "    stopwords = stopwords.split('\\n')\n",
    "\n",
    "     \n",
    "def is_alpha(token):\n",
    "    if re.match('[a-zA-Z]+$', token):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_words(doc):\n",
    "    for token in doc:\n",
    "        if is_alpha(token.orth_):\n",
    "            yield token    \n",
    "\n",
    "        \n",
    "def remove_step_words(doc):\n",
    "    for token in doc:\n",
    "        if token.lower_:\n",
    "            pass\n",
    "        \n",
    "def process(df):\n",
    "    column = []\n",
    "    for r in df['review']:\n",
    "        doc = nlp(r)\n",
    "        s = ''\n",
    "        for w in get_words(doc):\n",
    "            if not w.lower_ in stopwords:\n",
    "                s += w.lower_  + ' '\n",
    "        column.append(s)\n",
    "    return column\n",
    "\n",
    "train['tokens'] = process(train)\n",
    "test['tokens'] = process(test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>review</td>\n",
       "      <td>review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>stuff going moment mj started listening music ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>classic war timothy hines entertaining film ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>film starts manager nicholas bell giving welco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review  \\\n",
       "0      id  sentiment                                             review   \n",
       "1  5814_8          1  With all this stuff going down at the moment w...   \n",
       "2  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...   \n",
       "3  7759_3          0  The film starts with a manager (Nicholas Bell)...   \n",
       "\n",
       "                                              tokens  \n",
       "0                                            review   \n",
       "1  stuff going moment mj started listening music ...  \n",
       "2  classic war timothy hines entertaining film ob...  \n",
       "3  film starts manager nicholas bell giving welco...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Turning movie reviews into vectors with the help of word embeddings [Loading word embeddings - 2 points, feature matrix - 8 points]\n",
    "\n",
    "In the RNN demo, you saw how to load a pre-computed GloVe word embedding. Please repeat this to load in 50-dimensional GloVe word embedding vectors from `glove.6B.50d.txt`. \n",
    "\n",
    "A movie review is composed of words. Given a review, let's define a \"review embedding\" to be the average of the individual token (word) embeddings. Write a function to create a matrix whose rows are the review embeddings created as described in the previous sentence. If a word does not have a GloVe word embedding, ignore it. Each movie review now is an embedding vector which could be thought of as the feature vector for that movie review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nword_index = {}\\nindex = 0\\nfor tokens in test['tokens']:\\n    for word in tokens.split(' ')::\\n        print(word)\\n        if word not in word_index:\\n            word_index[word] = index\\n            index +=1\\n\\n\\n\\n# We first initialize the embedding matrix with zeros\\nembedding_matrix = np.zeros((max_words, embedding_dim))\\nfor word, i in word_index.items():\\n    # We get the word embeddings for each word from GloVe\\n    embedding_vector = embeddings_index.get(word)\\n    # We only look at top 10000 words\\n    if i< max_words:\\n        # if the embedding vector for the word exists in GloVe, we use it as the corresponding row in the \\n        # embedding matrix; otherwise we leave the row as all zeros\\n        if embedding_vector is not None:\\n            embedding_matrix[i] = embedding_vector\\n            \\n\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "# We will use the 100-dimensional embedding vectors\n",
    "with open(\"glove.6B.50d.txt\", encoding='utf-8') as f:\n",
    "    # Each row represents a word vector\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        # The first part is word\n",
    "        word = values[0]\n",
    "        # The rest are the embedding vector\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "word_index = {}\n",
    "index = 0\n",
    "for tokens in test['tokens']:\n",
    "    for word in tokens.split(' '):\n",
    "        if word not in word_index:\n",
    "            word_index[word] = index\n",
    "            index +=1\n",
    "\n",
    "for tokens in train['tokens']:\n",
    "    for word in tokens.split(' '):\n",
    "        if word not in word_index:\n",
    "            word_index[word] = index\n",
    "            index +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first initialize the embedding matrix with zeros\n",
    "embedding_dim = 50\n",
    "embedding_matrix = np.zeros((len(word_index.keys()), embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.37632999,  0.058652  ,  0.17005   ,  0.46862999,  0.95798999,\n",
       "        -0.82027   , -0.83683002,  0.53315002, -0.22664   , -1.15050006,\n",
       "         0.11026   ,  0.22662   , -0.80680001,  0.12202   ,  0.91294003,\n",
       "         0.39002001, -0.0051597 ,  0.11369   ,  0.45456001, -0.11737   ,\n",
       "        -0.074381  ,  1.50880003,  0.46654999,  0.04601   ,  0.68558002,\n",
       "        -2.28719997, -0.081728  ,  0.55559999, -1.12220001, -0.042912  ,\n",
       "         2.56509995, -0.12145   , -0.42656001, -0.11731   , -0.51801002,\n",
       "        -0.51683003,  0.58125001, -0.20615999,  0.67071998,  0.82279998,\n",
       "         0.21314   ,  1.36619997, -0.18691   , -0.78496999,  0.73258001,\n",
       "        -0.51868999, -1.53690004,  0.84912997,  0.51594001,  0.87638998],\n",
       "       [ 1.62450004, -0.71608001,  0.15488   ,  0.33987999, -0.54799998,\n",
       "         0.94953001,  0.53549999,  0.29616001,  0.78119999,  0.57072997,\n",
       "        -0.56431001, -0.98483998, -0.51095998,  0.40357   ,  0.39757001,\n",
       "        -0.31668001, -0.19241001,  0.32126001, -1.65639997,  0.75891   ,\n",
       "        -0.17253999,  0.063252  ,  0.76741999,  0.050658  , -0.17376   ,\n",
       "        -1.80270004, -0.09012   ,  0.301     ,  1.25119996,  0.60391003,\n",
       "         2.26979995, -0.34186   , -0.32104   , -0.74757999, -0.1123    ,\n",
       "         0.70134997,  0.076131  , -1.23440003, -0.34266999,  0.50625002,\n",
       "        -1.11989999,  0.18076   ,  0.050896  , -0.41139999,  2.07669997,\n",
       "         0.90487999, -0.084168  ,  0.17226   ,  0.20671   , -0.78889   ]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here for computing a 2D numpy array of review embeddings\n",
    "# (so the i-th movie review should having an embedding given by the i-th row of the 2D array)\n",
    "print(len(embedding_matrix))\n",
    "\n",
    "embedding_matrix[1:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) SVM [Cross Validation - 6 points, Correct Prediction - 4 Points]\n",
    "We now train a polynomial kernel SVM using the review embeddings from the previous part as feature vectors. But first, we have to figure out SVM parameter $C$ and also which polynomial degree $d$ to use! We do a grid search over $C$ in the range `np.logspace(-4, 2, 3)`, and polynomial degree $d$ in the range `range(1,4)`. For each parameter choice $(C, d)$, compute the 5-fold cross validation prediction accuracy (this will be the cross validation score for $(C, d)$). Across all choices of $(C, d)$ we will use whichever one has the highest cross validation score -- this will correspond to the best $C$ and best $d$. Then train the polynomial kernel SVM using the best $C$ and best $d$ and report the accuracy on the actual test data.\n",
    "\n",
    "Note that this problem involves writing grid search cross validation code (do NOT use scikit-learn or some external resource code that does this grid search for you; this problem is asking you to complete the grid search code below!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "num_folds = 5\n",
    "k_fold = KFold(num_folds)\n",
    "C_values = np.logspace(-4, 2, 3)\n",
    "D_values = range(1, 4)\n",
    "\n",
    "arg_max = None\n",
    "max_cross_val_score = -np.inf\n",
    "for C in C_values:\n",
    "    for d in D_values:\n",
    "        ################################################################################\n",
    "        # Write your code only in this block -- do not change code outside of this block!\n",
    "        # Hint: You will want to use `k_fold` (defined above) in conjunction with your\n",
    "        # training movie review feature vectors (these are the review embeddings) as\n",
    "        # well as training labels. The code here should *not* look at any part of the\n",
    "        # test data!\n",
    "        \n",
    "        cross_val_score = 0  # this should not actually be set to 0! set it to the cross validation SVM accuracy using parameters C and d\n",
    "        \n",
    "        ################################################################################\n",
    "\n",
    "        cross_val_score = np.mean(fold_scores)\n",
    "        if cross_val_score > max_cross_val_score:\n",
    "            max_cross_val_score = cross_val_score\n",
    "            arg_max = (C, d)\n",
    "            \n",
    "best_C, best_d = arg_max\n",
    "print(best_C, best_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write your code here that trains a polynomial kernel SVM using the best C and best d\n",
    "# (and the full training dataset), and then prints out the classifier accuracy on the\n",
    "# test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
